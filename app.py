import streamlit as st
import pandas as pd
import plotly.express as px
from st_aggrid import AgGrid, GridOptionsBuilder, JsCode
from datetime import datetime, timedelta
import jpholiday # â˜…è¿½åŠ : æ—¥æœ¬ã®ç¥æ—¥åˆ¤å®šãƒ©ã‚¤ãƒ–ãƒ©ãƒª

# --- â˜…è¨­å®š: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL ---
SHEET_URL = "https://docs.google.com/spreadsheets/d/1SEDGQLHGRN0rnXgLvP7wNzUuch6oxs9W4AvsavTagKM/export?format=csv"
MAPPING_URL = "https://docs.google.com/spreadsheets/d/1SEDGQLHGRN0rnXgLvP7wNzUuch6oxs9W4AvsavTagKM/export?format=csv&gid=59321871"

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ãƒ€ã‚¤ãƒŠãƒ å½¦æ ¹åˆ†æãƒ„ãƒ¼ãƒ«", layout="wide")

# ã‚¹ãƒãƒ›ç”¨ã«ã‚¿ã‚¤ãƒˆãƒ«æ–‡å­—ã‚’èª¿æ•´
st.markdown("<h2 style='font-size: 22px; margin-bottom: 0px;'>ğŸ° ãƒ€ã‚¤ãƒŠãƒ å½¦æ ¹åˆ†æãƒ„ãƒ¼ãƒ« (Proç‰ˆ)</h2>", unsafe_allow_html=True)

# --- 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
@st.cache_data(ttl=600)
def load_data():
    df = None
    if SHEET_URL:
        try:
            df = pd.read_csv(SHEET_URL)
        except Exception: pass
    
    if df is None:
        try:
            df = pd.read_csv("dynam_hikone_complete.csv")
        except FileNotFoundError: return None

    df.columns = df.columns.str.strip()
    rename_map = {
        "å°ç•ªå·": ["å°ç•ª", "No.", "No"],
        "æ©Ÿç¨®": ["æ©Ÿç¨®å", "Machine"],
        "ç·å·®æš": ["å·®æš", "å·®æšæ•°", "Diff"],
        "Gæ•°": ["ç·å›è»¢æ•°", "å›è»¢æ•°", "Games"],
    }
    for std, aliases in rename_map.items():
        if std not in df.columns:
            for alias in aliases:
                found = next((c for c in df.columns if alias in c), None)
                if found: df.rename(columns={found: std}, inplace=True); break

    if MAPPING_URL and "æ©Ÿç¨®" in df.columns:
        try:
            map_df = pd.read_csv(MAPPING_URL, header=None)
            if map_df.shape[1] >= 2:
                rename_dict = dict(zip(map_df.iloc[:, 0], map_df.iloc[:, 1]))
                df["æ©Ÿç¨®"] = df["æ©Ÿç¨®"].replace(rename_dict)
        except: pass

    numeric_cols = ["å°ç•ªå·", "ç·å·®æš", "Gæ•°"]
    for col in df.columns:
        if any(t in col for t in numeric_cols):
            try:
                df[col] = df[col].astype(str).str.replace(",", "").str.replace("+", "").str.replace(" ", "")
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
            except: pass

    if "æ—¥ä»˜" not in df.columns or "ç·å·®æš" not in df.columns: return None

    df["æ—¥ä»˜"] = pd.to_datetime(df["æ—¥ä»˜"])
    df["DayNum"] = df["æ—¥ä»˜"].dt.day
    df["Month"] = df["æ—¥ä»˜"].dt.month
    df["æœ«å°¾"] = df["DayNum"] % 10 
    
    # â˜…è¿½åŠ : æ›œæ—¥(0:æœˆã€œ6:æ—¥)ã¨ç¥æ—¥åˆ¤å®š
    df["æ›œæ—¥"] = df["æ—¥ä»˜"].dt.dayofweek
    df["is_Holiday"] = df["æ—¥ä»˜"].apply(lambda x: jpholiday.is_holiday(x.date()))

    # ã‚¾ãƒ­ç›®åˆ¤å®š (11/1ãªã©ã‚‚å«ã‚€)
    def check_is_zorome(row):
        d = row["DayNum"]
        m = row["Month"]
        if d in [11, 22]: return True
        if m == d: return True
        s = str(m) + str(d)
        if len(set(s)) == 1: return True
        return False

    df["is_Zorome"] = df.apply(check_is_zorome, axis=1)
    
    if "å°ç•ªå·" in df.columns:
        df["å°æœ«å°¾"] = df["å°ç•ªå·"] % 10
        def get_machine_zorome(num):
            s = str(num)
            if len(s) >= 2 and s[-1] == s[-2]: return s[-2:]
            return "é€šå¸¸" 
        df["å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—"] = df["å°ç•ªå·"].apply(get_machine_zorome)
    else:
        df["å°æœ«å°¾"] = 0
        df["å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—"] = "é€šå¸¸"

    return df

df = load_data()

if df is None:
    st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()

# --- æœ€æ–°æ©Ÿç¨®ãƒã‚¹ã‚¿ãƒ¼ä½œæˆ ---
latest_machine_map = {}
if "å°ç•ªå·" in df.columns and "æ©Ÿç¨®" in df.columns:
    try:
        temp_df = df.copy()
        temp_df["å°ç•ªå·"] = temp_df["å°ç•ªå·"].astype(int)
        latest_indices = temp_df.groupby("å°ç•ªå·")["æ—¥ä»˜"].idxmax()
        latest_machine_map = temp_df.loc[latest_indices].set_index("å°ç•ªå·")["æ©Ÿç¨®"].to_dict()
    except: pass

# --- ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºé–¢æ•° (å¹…å›ºå®š: æ©Ÿç¨®100, ä»–60) ---
def display_filterable_table(df_in, key_id):
    if df_in.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    with st.expander("ğŸ” **çµã‚Šè¾¼ã¿æ¡ä»¶ã‚’é–‹ã**", expanded=False):
        c1, c2 = st.columns(2)
        df_filtered = df_in.copy()
        if "æ©Ÿç¨®" in df_filtered.columns:
            all_machines = sorted(df_filtered["æ©Ÿç¨®"].astype(str).unique())
            with c1:
                selected_machines = st.multiselect("æ©Ÿç¨®", all_machines, key=f"filter_machine_{key_id}", placeholder="å…¨æ©Ÿç¨®")
            if selected_machines:
                df_filtered = df_filtered[df_filtered["æ©Ÿç¨®"].isin(selected_machines)]

        if "å¹³å‡å·®æš" in df_filtered.columns:
            with c2:
                min_diff = st.number_input("å¹³å‡å·®æšä»¥ä¸Š", value=0, step=100, key=f"filter_diff_{key_id}")
            df_filtered = df_filtered[df_filtered["å¹³å‡å·®æš"] >= min_diff]

        if "å‹ç‡" in df_filtered.columns:
            with c2:
                min_win = st.slider("å‹ç‡ä»¥ä¸Š(%)", 0, 100, 0, key=f"filter_win_{key_id}")
            df_filtered = df_filtered[df_filtered["å‹ç‡"] >= min_win]

    st.markdown(f"<small>æŠ½å‡ºä»¶æ•°: {len(df_filtered)} ä»¶</small>", unsafe_allow_html=True)

    gb = GridOptionsBuilder.from_dataframe(df_filtered)
    
 # å…¨åˆ—ã®åŸºæœ¬å¹…ã‚’60ã«è¨­å®š
    gb.configure_default_column(resizable=True, filterable=True, sortable=True, width=60, minWidth=40)

    fmt_comma = JsCode("""function(p){ return (p.value !== null && p.value !== undefined) ? p.value.toLocaleString() : ''; }""")
    fmt_percent = JsCode("""function(p){ return (p.value !== null && p.value !== undefined) ? Number(p.value).toFixed(1) + '%' : ''; }""")
    style_machine_wari = JsCode("""function(p){if(p.value>=105){return{'color':'white','backgroundColor':'#006400'};}if(p.value>=100){return{'backgroundColor':'#90EE90'};}return null;}""")
    style_diff = JsCode("""function(p){if(p.value>0){return{'color':'blue','fontWeight':'bold'};}if(p.value<0){return{'color':'red'};}return null;}""")
    style_status = JsCode("""function(p){if(p.value==='ğŸ’€æ’¤å»'){return{'color':'gray'};}return{'fontWeight':'bold'};}""")

    if "æ©Ÿç¨®" in df_filtered.columns: gb.configure_column("æ©Ÿç¨®", width=100)
    if "è¨­ç½®" in df_filtered.columns: gb.configure_column("è¨­ç½®", width=60, cellStyle=style_status)
    if "å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—" in df_filtered.columns: gb.configure_column("å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—", width=60)

    # â˜…åˆ—åã«ç‰¹å®šã®æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°è‡ªå‹•ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’é©ç”¨ã™ã‚‹
    for col in df_filtered.columns:
        if col in ["æ©Ÿç¨®", "è¨­ç½®", "å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—"]: continue
        
        if "æ©Ÿæ¢°å‰²" in col or "å‹ç‡" in col:
            c_style = style_machine_wari if "æ©Ÿæ¢°å‰²" in col else None
            gb.configure_column(col, valueFormatter=fmt_percent, cellStyle=c_style, type=["numericColumn"], width=60)
        elif "å·®æš" in col or "Gæ•°" in col or col in ["ã‚µãƒ³ãƒ—ãƒ«æ•°", "å°ç•ªå·", "å°æœ«å°¾"]:
            c_style = style_diff if "å·®æš" in col else None
            gb.configure_column(col, valueFormatter=fmt_comma, cellStyle=c_style, type=["numericColumn"], width=60)

    grid_options = gb.build()
    
    AgGrid(
        df_filtered,
        gridOptions=grid_options,
        allow_unsafe_jscode=True,
        height=400,
        theme="ag-theme-alpine", 
        key=f"grid_{key_id}",
        fit_columns_on_grid_load=False # æŒ‡å®šã—ãŸå¹…ã‚’å³å¯†ã«å®ˆã‚‹
    )

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("ğŸ¯ æˆ¦ç•¥è¨­å®š")

min_d_data = df["æ—¥ä»˜"].min().date()
max_d_data = df["æ—¥ä»˜"].max().date()
today = datetime.now().date()

# æœŸé–“ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
if "range_input" not in st.session_state:
    st.session_state["range_input"] = [min_d_data, max_d_data]

def apply_range(days=None):
    if days is None:
        new_range = [min_d_data, max_d_data]
    else:
        start = max(today - timedelta(days=days), min_d_data)
        end = min(today, max_d_data)
        new_range = [start, end]
    st.session_state["range_input"] = new_range
    st.rerun()

st.sidebar.markdown("ğŸ“… **æœŸé–“ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ**")
col_b1, col_b2 = st.sidebar.columns(2)
if col_b1.button("å…¨æœŸé–“"): apply_range(None)
if col_b2.button("éå»14æ—¥"): apply_range(14)

col_b3, col_b4, col_b5 = st.sidebar.columns(3)
if col_b3.button("éå»30æ—¥"): apply_range(30)
if col_b4.button("éå»60æ—¥"): apply_range(60)
if col_b5.button("éå»90æ—¥"): apply_range(90)

# ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å…¥åŠ›
st.sidebar.markdown("<br>", unsafe_allow_html=True) 

dates = st.sidebar.date_input(
    "åˆ†ææœŸé–“ã‚’æŒ‡å®š",
    min_value=min_d_data,
    max_value=max_d_data,
    format="YYYY/MM/DD",
    key="range_input" 
)

# æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
if len(dates) == 2:
    start_date, end_date = dates
    df = df[(df["æ—¥ä»˜"].dt.date >= start_date) & (df["æ—¥ä»˜"].dt.date <= end_date)]
elif len(dates) == 1:
    start_date = dates[0]
    df = df[df["æ—¥ä»˜"].dt.date == start_date]

st.sidebar.markdown("---")
if st.sidebar.checkbox("ğŸ“‹ å…ƒã®æ©Ÿç¨®åä¸€è¦§ã‚’è¡¨ç¤º"):
    if "æ©Ÿç¨®" in df.columns:
        raw_machines = sorted(df["æ©Ÿç¨®"].unique())
        st.sidebar.text_area("å…¨æ©Ÿç¨®åãƒªã‚¹ãƒˆ", "\n".join(map(str, raw_machines)), height=200)

if st.sidebar.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æœ€æ–°ã«æ›´æ–°"):
    st.cache_data.clear()
    st.rerun()

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“… æ—¥ä»˜ãƒ»æ¡ä»¶ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")

target_ends = st.sidebar.multiselect("â‘  æ—¥ä»˜ã®æœ«å°¾ (0-9)", options=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], default=[])
use_zorome = st.sidebar.checkbox("â‘¡ ã‚¾ãƒ­ç›®ã®æ—¥ã‚’å«ã‚ã‚‹ (11/1ç­‰ã‚‚å«ã‚€)", value=False)
# â˜…è¿½åŠ : åœŸæ—¥ç¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
use_saturday = st.sidebar.checkbox("â‘¢ åœŸæ›œæ—¥ã‚’å«ã‚ã‚‹", value=False)
use_sunday = st.sidebar.checkbox("â‘£ æ—¥æ›œæ—¥ã‚’å«ã‚ã‚‹", value=False)
use_holiday = st.sidebar.checkbox("â‘¤ ç¥æ—¥ã‚’å«ã‚ã‚‹", value=False)

mask = pd.Series([False] * len(df), index=df.index)

# â˜…ä¿®æ­£: ã©ã‚Œã‹1ã¤ã§ã‚‚ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒã‚ªãƒ³ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèª
is_any_filter_active = bool(target_ends) or use_zorome or use_saturday or use_sunday or use_holiday

if is_any_filter_active:
    if target_ends: mask = mask | df["æœ«å°¾"].isin(target_ends)
    if use_zorome: mask = mask | df["is_Zorome"]
    if use_saturday: mask = mask | (df["æ›œæ—¥"] == 5) # 5ã¯åœŸæ›œæ—¥
    if use_sunday: mask = mask | (df["æ›œæ—¥"] == 6)   # 6ã¯æ—¥æ›œæ—¥
    if use_holiday: mask = mask | df["is_Holiday"]   # ç¥æ—¥åˆ¤å®š
    target_df = df[mask].copy()
else:
    target_df = df.copy() # ä½•ã‚‚é¸ã°ã‚Œã¦ã„ãªã„å ´åˆã¯å…¨ãƒ‡ãƒ¼ã‚¿

if target_df.empty:
    st.warning("æ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# --- å…±é€šè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ (Gæ•°0é™¤å¤–) ---
def calculate_metrics(dataframe, group_cols):
    dataframe = dataframe[dataframe["Gæ•°"] > 0] # ç¨¼åƒãªã—ã‚’é™¤å¤–

    agg = dataframe.groupby(group_cols).agg(
        ã‚µãƒ³ãƒ—ãƒ«æ•°=("ç·å·®æš", "count"),
        å‹æ•°=("ç·å·®æš", lambda x: (x > 0).sum()),
        ç·å·®æš=("ç·å·®æš", "sum"),
        ç·Gæ•°=("Gæ•°", "sum"),
        å¹³å‡å·®æš=("ç·å·®æš", "mean"),
        å¹³å‡Gæ•°=("Gæ•°", "mean")
    ).reset_index()
    
    agg["å‹ç‡"] = (agg["å‹æ•°"] / agg["ã‚µãƒ³ãƒ—ãƒ«æ•°"] * 100).round(1)
    agg["æ©Ÿæ¢°å‰²"] = agg.apply(
        lambda x: ((x["ç·Gæ•°"]*3 + x["ç·å·®æš"]) / (x["ç·Gæ•°"]*3) * 100) if x["ç·Gæ•°"] > 0 else 0, 
        axis=1
    ).round(1)
    
    agg["å¹³å‡å·®æš"] = agg["å¹³å‡å·®æš"].fillna(0).round(0).astype(int)
    agg["å¹³å‡Gæ•°"] = agg["å¹³å‡Gæ•°"].fillna(0).round(0).astype(int)
    return agg

# â˜…ä¿®æ­£: ã‚¿ã‚¤ãƒˆãƒ«ã«åœŸæ—¥ç¥ã‚’åæ˜ 
title_parts = []
if target_ends: title_parts.append(f"æœ«å°¾{target_ends}")
if use_zorome: title_parts.append("ã‚¾ãƒ­ç›®")
if use_saturday: title_parts.append("åœŸæ›œ")
if use_sunday: title_parts.append("æ—¥æ›œ")
if use_holiday: title_parts.append("ç¥æ—¥")
title_str = " & ".join(title_parts) if title_parts else "å…¨æœŸé–“"

# ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ã‚‚ã‚¹ãƒãƒ›ç”¨ã«èª¿æ•´ã—ã€æ­£ã—ã„ä½ç½®ã«é…ç½®
st.markdown(f"<div style='font-size: 16px; font-weight: bold; margin-top: 15px; margin-bottom: 10px;'>ğŸ¯ åˆ†æå¯¾è±¡: {title_str}</div>", unsafe_allow_html=True)

# === ã‚¿ãƒ–æ§‹æˆ ===
tab1, tab2, tab3, tab4 = st.tabs([
    "â‘  æœ«å°¾ãƒ»å°ç•ªã‚¾ãƒ­ç›®", 
    "â‘¡ é‰„æ¿å°ãƒ©ãƒ³ã‚­ãƒ³ã‚°", 
    "â‘¢ æ©Ÿç¨®åˆ¥", 
    "â‘£ æ©Ÿç¨®Ã—æœ«å°¾ãƒ»ã‚¾ãƒ­ç›®"
])

# ==========================================
# 1. æœ«å°¾ãƒ»å°ç•ªã‚¾ãƒ­ç›®
# ==========================================
with tab1:
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ…°ï¸ é€šå¸¸ã®ã€Œå°æœ«å°¾ (0-9)ã€")
        if "å°ç•ªå·" in target_df.columns:
            matsubi_metrics = calculate_metrics(target_df, ["å°æœ«å°¾"])
            fig1 = px.bar(matsubi_metrics, x="å°æœ«å°¾", y="å¹³å‡å·®æš", 
                          color="æ©Ÿæ¢°å‰²", color_continuous_scale="RdYlGn",
                          text="æ©Ÿæ¢°å‰²", title="æœ«å°¾ (0-9) ã®å¹³å‡å·®æš")
            fig1.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
            fig1.update_yaxes(tickformat=",")
            fig1.update_layout(xaxis=dict(tickmode='linear', dtick=1))
            st.plotly_chart(fig1, use_container_width=True)
            display_filterable_table(
                matsubi_metrics[["å°æœ«å°¾", "å‹ç‡", "å¹³å‡å·®æš", "å¹³å‡Gæ•°", "æ©Ÿæ¢°å‰²", "ã‚µãƒ³ãƒ—ãƒ«æ•°"]],
                key_id="tab1_norm"
            )

    with col2:
        st.subheader("ğŸ…±ï¸ ã€Œå°ç•ªã‚¾ãƒ­ç›®ã€")
        zorome_df = target_df[target_df["å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—"] != "é€šå¸¸"]
        if zorome_df.empty:
            st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")
        else:
            zorome_metrics = calculate_metrics(zorome_df, ["å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—"])
            fig2 = px.bar(zorome_metrics, x="å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—", y="å¹³å‡å·®æš", 
                          color="æ©Ÿæ¢°å‰²", color_continuous_scale="RdYlGn",
                          text="æ©Ÿæ¢°å‰²", title="å°ç•ªã‚¾ãƒ­ç›® (11ã€œ00) ã®å¹³å‡å·®æš")
            fig2.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
            fig2.update_yaxes(tickformat=",")
            st.plotly_chart(fig2, use_container_width=True)
            display_filterable_table(
                zorome_metrics[["å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—", "å‹ç‡", "å¹³å‡å·®æš", "å¹³å‡Gæ•°", "æ©Ÿæ¢°å‰²", "ã‚µãƒ³ãƒ—ãƒ«æ•°"]],
                key_id="tab1_zorome"
            )

# ==========================================
# 2. é‰„æ¿å°ãƒ©ãƒ³ã‚­ãƒ³ã‚°
# ==========================================
with tab2:
    st.subheader(f"â‘¡ {title_str} ã®é‰„æ¿å°ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    if "å°ç•ªå·" not in target_df.columns:
        st.error("å°ç•ªå·ãªã—")
    else:
        c1, c2, c3 = st.columns([1, 1, 1])
        with c1: min_sample = st.slider("æœ€ä½ç¨¼åƒå›æ•°", 1, 10, 1, key="tab2_s1")
        with c2: min_diff_map = st.slider("æœ€ä½å¹³å‡å·®æš", -1000, 2000, 0, step=100, key="tab2_s2")
        with c3:
            st.write(""); st.write("")
            only_active = st.checkbox("ğŸŸ¢ ç¾å½¹å°ã®ã¿è¡¨ç¤º", value=True)

        daiban_metrics = calculate_metrics(target_df, ["å°ç•ªå·", "æ©Ÿç¨®"])
        filtered = daiban_metrics[
            (daiban_metrics["ã‚µãƒ³ãƒ—ãƒ«æ•°"] >= min_sample) & 
            (daiban_metrics["å¹³å‡å·®æš"] >= min_diff_map)
        ].copy()
        
        if filtered.empty:
            st.warning("æ¡ä»¶ã«åˆã†ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            def check_status(row):
                try:
                    t_no = int(row["å°ç•ªå·"])
                    current = latest_machine_map.get(t_no)
                    if current and str(current).strip() == str(row["æ©Ÿç¨®"]).strip(): return "ğŸŸ¢ç¾å½¹"
                    else: return "ğŸ’€æ’¤å»"
                except: return "â“ä¸æ˜"
            
            filtered["è¨­ç½®"] = filtered.apply(check_status, axis=1)
            if only_active: filtered = filtered[filtered["è¨­ç½®"] == "ğŸŸ¢ç¾å½¹"]

            if filtered.empty:
                 st.warning("æ¡ä»¶ã«åˆã†ç¾å½¹å°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                filtered["è¡¨ç¤ºå"] = filtered["è¨­ç½®"] + " " + filtered["å°ç•ªå·"].astype(str) + " (" + filtered["æ©Ÿç¨®"] + ")"
                fig = px.scatter(filtered, x="å‹ç‡", y="å¹³å‡å·®æš", size="ã‚µãƒ³ãƒ—ãƒ«æ•°", color="æ©Ÿæ¢°å‰²", 
                                 hover_name="è¡¨ç¤ºå", text="å°ç•ªå·", color_continuous_scale="RdYlGn",
                                 symbol="è¨­ç½®", title="å‹ç‡ vs å¹³å‡å·®æš")
                fig.add_hline(y=0, line_dash="dash", line_color="gray")
                fig.add_vline(x=50, line_dash="dash", line_color="gray")
                fig.update_xaxes(tickformat=".1f", title_text="å‹ç‡ (%)")
                fig.update_yaxes(tickformat=",", title_text="å¹³å‡å·®æš (æš)")
                fig.update_traces(hovertemplate="<b>%{hovertext}</b><br>å‹ç‡: %{x:.1f}%<br>å¹³å‡å·®æš: %{y:,}æš<br>æ©Ÿæ¢°å‰²: %{marker.color:.1f}%<br>ã‚µãƒ³ãƒ—ãƒ«: %{marker.size}")
                st.plotly_chart(fig, use_container_width=True)
                
               # åŸºæœ¬ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”¨ãƒ‡ãƒ¼ã‚¿ (ã”æŒ‡å®šã®ä¸¦ã³é †)
                disp_df = filtered[["å°ç•ªå·", "æ©Ÿç¨®", "å‹ç‡", "æ©Ÿæ¢°å‰²", "å¹³å‡å·®æš", "å¹³å‡Gæ•°", "ç·å·®æš", "ã‚µãƒ³ãƒ—ãƒ«æ•°", "è¨­ç½®"]].sort_values(["è¨­ç½®", "æ©Ÿæ¢°å‰²"], ascending=[True, False])
                
                # --- â˜…è¿½åŠ : æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã®æ¨ªå±•é–‹ï¼ˆãƒ”ãƒœãƒƒãƒˆï¼‰å‡¦ç† ---
                # è©²å½“ã™ã‚‹å°ã®å…ƒãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                daily_df = target_df[["å°ç•ªå·", "æ©Ÿç¨®", "æ—¥ä»˜", "Gæ•°", "ç·å·®æš"]].copy()
                
                # æ—¥åˆ¥ã®æ©Ÿæ¢°å‰²ã‚’è¨ˆç®—
                daily_df["æ©Ÿæ¢°å‰²"] = daily_df.apply(lambda x: ((x["Gæ•°"]*3 + x["ç·å·®æš"])/(x["Gæ•°"]*3)*100) if x["Gæ•°"]>0 else 0, axis=1).round(1)
                
                # æ—¥ä»˜ã‚’ã€ŒMM/DDã€å½¢å¼ã«ã™ã‚‹
                daily_df["æ—¥ä»˜æ–‡å­—"] = daily_df["æ—¥ä»˜"].dt.strftime('%m/%d')
                
                # å°ç•ªãƒ»æ©Ÿç¨®ã‚’è»¸ã«ã—ã¦ã€æ—¥ä»˜ã”ã¨ã®Gæ•°ãƒ»å·®æšãƒ»æ©Ÿæ¢°å‰²ã‚’æ¨ªã«ä¸¦ã¹ã‚‹
                pivot_df = daily_df.pivot_table(index=["å°ç•ªå·", "æ©Ÿç¨®"], columns="æ—¥ä»˜æ–‡å­—", values=["Gæ•°", "ç·å·®æš", "æ©Ÿæ¢°å‰²"], aggfunc="first")
                
                if not pivot_df.empty:
                    # åˆ—åã‚’ã€Œ02/01_Gæ•°ã€ã®ã‚ˆã†ã«çµåˆã—ã¦ãƒ•ãƒ©ãƒƒãƒˆã«ã™ã‚‹
                    pivot_df.columns = [f"{col[1]}_{col[0]}" for col in pivot_df.columns]
                    pivot_df.reset_index(inplace=True)
                    
                    # æ—¥ä»˜é †ã€ã‹ã¤ã€ŒGæ•° â†’ å·®æš â†’ æ©Ÿæ¢°å‰²ã€ã®é †ã«åˆ—ã‚’ä¸¦ã³æ›¿ãˆã‚‹
                    date_strs = sorted(daily_df["æ—¥ä»˜æ–‡å­—"].unique())
                    ordered_cols = ["å°ç•ªå·", "æ©Ÿç¨®"]
                    for d in date_strs:
                        ordered_cols.extend([f"{d}_Gæ•°", f"{d}_ç·å·®æš", f"{d}_æ©Ÿæ¢°å‰²"])
                    available_cols = [c for c in ordered_cols if c in pivot_df.columns]
                    pivot_df = pivot_df[available_cols]
                    
                    # disp_df ã«æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’åˆä½“ï¼ˆãƒãƒ¼ã‚¸ï¼‰
                    disp_df = pd.merge(disp_df, pivot_df, on=["å°ç•ªå·", "æ©Ÿç¨®"], how="left")
                # ------------------------------------------------

                # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                csv = disp_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name='teppan_ranking.csv',
                    mime='text/csv',
                    key='download_tab2'
                )

                display_filterable_table(disp_df, key_id="tab2_ranking")

# ==========================================
# 3. æ©Ÿç¨®åˆ¥
# ==========================================
with tab3:
    st.subheader("â‘¢ æ©Ÿç¨®åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    model_metrics = calculate_metrics(target_df, ["æ©Ÿç¨®"])
    min_model = st.slider("æœ€ä½ç¨¼åƒå°æ•°", 1, 10, 1, key="tab3_slider")
    model_metrics = model_metrics[model_metrics["ã‚µãƒ³ãƒ—ãƒ«æ•°"] >= min_model]
    
    if not model_metrics.empty:
        model_metrics = model_metrics.sort_values("ç·å·®æš", ascending=False).head(20)
        fig3 = px.bar(model_metrics, x="æ©Ÿæ¢°å‰²", y="æ©Ÿç¨®", orientation='h', color="ç·å·®æš", 
                      color_continuous_scale="RdYlGn", text="æ©Ÿæ¢°å‰²")
        fig3.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
        fig3.update_xaxes(tickformat=".1f", title_text="æ©Ÿæ¢°å‰² (%)")
        st.plotly_chart(fig3, use_container_width=True)
        display_filterable_table(
            model_metrics[["æ©Ÿç¨®", "æ©Ÿæ¢°å‰²", "å‹ç‡", "å¹³å‡å·®æš", "å¹³å‡Gæ•°", "ã‚µãƒ³ãƒ—ãƒ«æ•°"]],
            key_id="tab3_model"
        )

# ==========================================
# 4. æ©Ÿç¨® Ã— æœ«å°¾
# ==========================================
with tab4:
    st.subheader("â‘£ æ©Ÿç¨® Ã— æœ«å°¾ãƒ»ã‚¾ãƒ­ç›® ã®æ³•å‰‡")
    top_models = target_df["æ©Ÿç¨®"].value_counts().head(10).index.tolist()
    sel_models = st.multiselect("æ©Ÿç¨®é¸æŠ", sorted(target_df["æ©Ÿç¨®"].unique()), default=top_models)

    if sel_models:
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("##### ğŸ…°ï¸ æ©Ÿç¨® Ã— é€šå¸¸æœ«å°¾")
            df_heat = target_df[target_df["Gæ•°"] > 0]
            cross_norm = df_heat.groupby(["æ©Ÿç¨®", "å°æœ«å°¾"]).agg(ç·å·®æš=("ç·å·®æš", "sum"), ç·G=("Gæ•°", "sum")).reset_index()
            cross_norm["æ©Ÿæ¢°å‰²"] = cross_norm.apply(lambda x: ((x["ç·G"]*3 + x["ç·å·®æš"])/(x["ç·G"]*3)*100) if x["ç·G"]>0 else 0, axis=1).round(1)
            filt_norm = cross_norm[cross_norm["æ©Ÿç¨®"].isin(sel_models)]
            if not filt_norm.empty:
                hm_norm = filt_norm.pivot(index="æ©Ÿç¨®", columns="å°æœ«å°¾", values="æ©Ÿæ¢°å‰²").fillna(0)
                fig4 = px.imshow(hm_norm, labels=dict(x="æœ«å°¾", y="æ©Ÿç¨®", color="æ©Ÿæ¢°å‰²"), 
                                     zmin=90, zmax=110, aspect="auto", text_auto=True, color_continuous_scale="RdYlGn")
                fig4.update_traces(texttemplate="%{z:.1f}%", hovertemplate="æ©Ÿç¨®: %{y}<br>æœ«å°¾: %{x}<br>æ©Ÿæ¢°å‰²: %{z:.1f}%")
                st.plotly_chart(fig4, use_container_width=True)
            else: st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")

        with c2:
            st.markdown("##### ğŸ…±ï¸ æ©Ÿç¨® Ã— å°ç•ªã‚¾ãƒ­ç›®")
            zorome_df_only = df_heat[df_heat["å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—"] != "é€šå¸¸"]
            cross_zorome = zorome_df_only.groupby(["æ©Ÿç¨®", "å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—"]).agg(ç·å·®æš=("ç·å·®æš", "sum"), ç·G=("Gæ•°", "sum")).reset_index()
            cross_zorome["æ©Ÿæ¢°å‰²"] = cross_zorome.apply(lambda x: ((x["ç·G"]*3 + x["ç·å·®æš"])/(x["ç·G"]*3)*100) if x["ç·G"]>0 else 0, axis=1).round(1)
            filt_zorome = cross_zorome[cross_zorome["æ©Ÿç¨®"].isin(sel_models)]
            if not filt_zorome.empty:
                hm_zorome = filt_zorome.pivot(index="æ©Ÿç¨®", columns="å°ã‚¾ãƒ­ç›®ã‚¿ã‚¤ãƒ—", values="æ©Ÿæ¢°å‰²").fillna(0)
                fig5 = px.imshow(hm_zorome, labels=dict(x="ã‚¾ãƒ­ç›®", y="æ©Ÿç¨®", color="æ©Ÿæ¢°å‰²"), 
                                     zmin=90, zmax=110, aspect="auto", text_auto=True, color_continuous_scale="RdYlGn")
                fig5.update_traces(texttemplate="%{z:.1f}%", hovertemplate="æ©Ÿç¨®: %{y}<br>ã‚¾ãƒ­ç›®: %{x}<br>æ©Ÿæ¢°å‰²: %{z:.1f}%")
                st.plotly_chart(fig5, use_container_width=True)
            else: st.info("ã‚¾ãƒ­ç›®ãƒ‡ãƒ¼ã‚¿ãªã—")




